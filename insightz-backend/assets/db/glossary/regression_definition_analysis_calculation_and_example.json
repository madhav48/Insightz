{
  "term": "Regression: Definition, Analysis, Calculation, and Example",
  "definition": "David is comprehensively experienced in many facets of financial and legal research and publishing. As an Investopedia fact checker since 2020, he has validated over 1,100 articles on a wide range of financial and investment topics.\n\nRegression tries to determine how a dependent variable and one or more other (independent) variables relate to each other. It\u2019s a statistical method.\n\nRegression\u00a0is a statistical method that analyzes the relationship between a dependent variable and one or more independent variables. It helps predict or understand how changes in the independent variable(s) are associated with changes in the dependent variable.\n\nLinear regression is the most common form of this technique. It establishes thelinear relationshipbetween two variables and is also referred to as simple regression or ordinary least squares (OLS) regression.\n\nLinear regression is graphically depicted using a straightline of best fit, with the slope defining how the change in one variable impacts a change in the other. The y-intercept of a linear regression relationship represents the value of the dependent variable when the value of the independent variable is zero.Nonlinear regressionmodels also exist but are far more complex.\n\nRegression is used in economics to help investment managers value assets and understand the relationships between factors such ascommodityprices and thestocksof businesses dealing in those commodities. It\u2019s a powerful tool for uncovering the associations between variables observed in data, but it can\u2019t easily indicate causation.\n\nRegression as a statistical technique shouldn\u2019t be confused with the concept of regression to the mean, also known asmean reversion.\n\nRegression captures the correlation between variables observed in a dataset and quantifies whether those correlations arestatistically significant. The two basic types of regression are simple linear regression andmultiple linear regression, but there are nonlinear regression methods for more complicated data and analysis.\n\nSimple linear regression uses one independent variable to explain or predict the outcome of the dependent variable Y. Multiple linear regression uses two or more independent variables to predict the outcome. Analysts can usestepwise regressionto examine each independent variable contained in the linear regression model.\n\nRegression can help finance and investment professionals. A company might use it to predict sales based on weather, previous sales, gross domestic product (GDP) growth, or other types of conditions. Thecapital asset pricing model (CAPM)is a regression model that\u2019s often used in finance for pricing assets and discovering the costs of capital.\n\nEconometricsis a set of statistical techniques that are used to analyze data in finance and economics. It effectively studies the income effect using observable data. An economist might hypothesize that a consumer\u2019s spending will increase as they increase theirincome.\n\nA regression analysis can then be conducted to understand the strength of the relationship between income and consumption if the data show that such an association is present. It can indicate whether that relationship is statistically significant.\n\nYou can have several independent variables in an analysis, such as changes to GDP and inflation in addition to unemployment in explaining stock market prices. It\u2019s referred to as\u00a0multiple linear regression when more than one independent variable is used. This is the most commonly used tool in econometrics.\n\nEconometrics is sometimes criticized for relying too heavily on the interpretation of regression output without linking it to economic theory or looking for causal mechanisms. It\u2019s crucial that the findings revealed in the data can be adequately explained by a theory.\n\nLinear regression models often use a least-squares approach to determine the line of best fit. The least-squares technique is determined by minimizing thesum of squarescreated by a mathematical function. A square is then determined by squaring the distance between a data point and the regression line or mean value of the dataset.\n\nA regression model is constructed when this process has been completed. It\u2019s usually accomplished with software. The general form of each type of regression model is:\n\nY=a+bX+u\\begin{aligned}&Y = a + bX + u \\\\\\end{aligned}\u200bY=a+bX+u\u200b\n\nY=a+b1X1+b2X2+b3X3+...+btXt+uwhere:Y=The\u00a0dependent\u00a0variable\u00a0you\u00a0are\u00a0trying\u00a0to\u00a0predictor\u00a0explainX=The\u00a0explanatory\u00a0(independent)\u00a0variable(s)\u00a0you\u00a0areusing\u00a0to\u00a0predict\u00a0or\u00a0associate\u00a0with\u00a0Ya=The\u00a0y-interceptb=(beta\u00a0coefficient)\u00a0is\u00a0the\u00a0slope\u00a0of\u00a0the\u00a0explanatoryvariable(s)u=The\u00a0regression\u00a0residual\u00a0or\u00a0error\u00a0term\\begin{aligned}&Y = a + b_1X_1 + b_2X_2 + b_3X_3 + ... + b_tX_t + u \\\\&\\textbf{where:} \\\\&Y = \\text{The dependent variable you are trying to predict} \\\\&\\text{or explain} \\\\&X = \\text{The explanatory (independent) variable(s) you are } \\\\&\\text{using to predict or associate with Y} \\\\&a = \\text{The y-intercept} \\\\&b = \\text{(beta coefficient) is the slope of the explanatory} \\\\&\\text{variable(s)} \\\\&u = \\text{The regression residual or error term} \\\\\\end{aligned}\u200bY=a+b1\u200bX1\u200b+b2\u200bX2\u200b+b3\u200bX3\u200b+...+bt\u200bXt\u200b+uwhere:Y=The\u00a0dependent\u00a0variable\u00a0you\u00a0are\u00a0trying\u00a0to\u00a0predictor\u00a0explainX=The\u00a0explanatory\u00a0(independent)\u00a0variable(s)\u00a0you\u00a0areusing\u00a0to\u00a0predict\u00a0or\u00a0associate\u00a0with\u00a0Ya=The\u00a0y-interceptb=(beta\u00a0coefficient)\u00a0is\u00a0the\u00a0slope\u00a0of\u00a0the\u00a0explanatoryvariable(s)u=The\u00a0regression\u00a0residual\u00a0or\u00a0error\u00a0term\u200b\n\nRegression is often used to determine how specific factors such as the price of a commodity, interest rates, particular industries, or sectors influence the price movement of an asset. The CAPM is based on regression and is used to project the expected returns for stocks and generate costs of capital. A stock\u2019s returns are regressed against the returns of a broader index such as the S&P 500 to generate abetafor the particular stock.\n\nBeta is the stock\u2019s risk in relation to the market or index, and it\u2019s reflected as the slope in the CAPM. The return for the stock in question would be the dependent variable Y. The independent variable X would be the market risk premium.\n\nAdditional variables such as the market capitalization of a stock, valuation ratios, and recent returns can be added to the CAPM to get better estimates for returns. These additional factors are known as the Fama-French factors. They\u2019re named after the professors who developed the multiple linear regression model to better explain asset returns.\n\nRegression tries to see if there\u2019s a relationship between two things, such as whether there\u2019s a link between how you do one thing and how you do one or more other things.\n\nRegression helps you make educated guesses, or predictions, based on past information. It\u2019s about finding a pattern between two or more things and using that pattern to make a good guess about what might happen in the future.\n\nThere\u2019s some debate about the origins of the name, but this statistical technique was most likely termed \u201cregression\u201d by Sir Francis Galton in the 19th century. It described the statistical feature of biological data, such as the heights of people in a population, to regress to a mean level. There are shorter and taller people, but only outliers are very tall or short, and most people cluster somewhere around or \u201cregress\u201d to the average.\n\nRegression is used in statistical analysis to identify the associations between variables occurring in some data. It can show the magnitude of such an association and determine its statistical significance. Regression is a powerful tool for statistical inference and has been used to try to predict future outcomes based on past observations.\n\nA regression model output may be in the form of Y = 1.0 + (3.2)X1- 2.0(X2) + 0.21.\n\nHere we have a multiple linear regression that relates some variable Y with two explanatory variables X1and X2. We would interpret the model as the value of Y changes by 3.2\u00d7 for every one-unit change in X1.If X1goes up by 2, Y goes up by 6.4, holding all else constant.\n\nThis means that when controlling for X2, X1has this observed relationship. Every one-unit increase in X2is associated with a 2\u00d7 decreasein Y if X1holds constant. We can also note the y-intercept of 1.0, indicating that Y = 1 when X1and X2are both zero. Theerror termor residual is 0.21.\n\nFour main assumptions about the underlying data process of what you\u2019re analyzing must hold to properly interpret the output of a regression model:\n\nRegression is a statistical method that tries to determine the strength and character of the relationship between one dependent variable and a series of other variables. It\u2019s used in finance, investing, and other disciplines.\n\nRegression analysis uncovers the associations between variables observed in data, but it can\u2019t easily indicate causation.\n\nFama, Eugene F., and Kenneth R. French. \u201cThe Cross-Section of Expected Stock Returns.\u201dThe Journal of Finance, vol. 47, no. 2, June 1992, pp. 427\u2013465.\n\nStanton, Jeffrey M. \u201cGalton, Pearson, and the Peas: A Brief History of Linear Regression for Statistics Instructors.\u201dJournal of Statistics Education, vol. 9, no. 3, 2001.\n\nBarbara Illowsky et al. \u201cQuantitative Analysis for Business: 13. Multiple Linear Regression.\u201d\u00a0University of Washington Pressbooks, 2022.\n\nCFA Institute. \u201cBasics Of Multiple Regression and Underlying Assumptions.\u201d",
  "url": "https://www.investopedia.com/terms/r/regression.asp"
}