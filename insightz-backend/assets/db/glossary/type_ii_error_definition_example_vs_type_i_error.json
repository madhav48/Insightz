{
  "term": "Type II Error: Definition, Example, vs. Type I Error",
  "definition": "Suzanne is a content marketer, writer, and fact-checker.\u00a0She holds a Bachelor of Science in Finance degree from Bridgewater State University and helps develop content strategies.\n\nMichela Buttignol / Investopedia\n\nA type II error, also known as a false negative, is the miscalculation that occurs when a researcher accepts a false null hypothesis.\n\nA type II error is a statistical term used to describe the error that results when a null hypothesis that is actually false is not rejected by an investigator or researcher.A type II error produces a false negative, also known as an error of omission.\n\nA type II error can be contrasted with a type I error, where researchers incorrectly reject a true null hypothesis.\n\nWhen testing a statistical hypothesis, there are two primary types: the null hypothesis and the alternative hypothesis.\n\nThe null hypothesis generally suggests that for the data being evaluated, there is no difference between groups or no relationships between variables.\n\nThe alternative hypothesis would state the researcher's expectations (their claims), such as what they expect to find between variables. Like everyone else, researchers can make errors in their assumptions.\n\nA type II error, also known as an error of the second kind or a beta error, confirms that a null hypothesis should have been rejected (because two variables that were claimed to be unrelated actually were related).\n\nA researcher makes a type II error in this instance by not rejecting the null hypothesis\u2014that is, by not rejecting the idea that two variables are unrelated after the research is completed and it's proven false.\n\nThe likelihood of making a type II error can be reduced by creating more stringent criteria for rejecting a null hypothesis (H0).\n\nFor example, if an analyst is considering anything that falls within the +/- bounds of a 95%confidence intervalas statistically insignificant (a negative result), then by decreasing that tolerance to +/- 90%, and subsequently narrowing the bounds, you will get fewer negative results, and thus reduce the chances of a false negative.\n\nTaking these steps, however, tends to increase the chances of encountering a type I error\u2014a false-positive result.\n\nWhen conducting a hypothesis test, the probability or risk of making a\u00a0type I error\u00a0or type II error should be considered.\n\nThe steps taken to reduce the probability of a type II error tend to increase the probability of a type I error.\n\nThe difference between a type II error and a type I error is that a type I error rejects the null hypothesis when it is true (i.e., a false positive).\n\nThe probability of committing a type I error is equal to thelevel of significancethat was set for the hypothesis test. Therefore, if the level of significance is 0.05, there is a 5% chance that a type I error may occur.\n\nThe probability of committing a type II error is equal to one minus the power of the test, also known as beta. The power of the test could be raised by increasing thesamplesize, which decreases the risk of committing a type II error.\n\nSome statistical literature will include overall significance level and type II error risk as part of the report\u2019s analysis. For example, a 2021 meta-analysis of exosome in the treatment of spinal cord injury recorded an overall significance level of 0.05 and a type II error risk of 0.1.\n\nAssume a biotechnology company wants to compare how effective two of its drugs are for treating diabetes.\n\nThe null hypothesis (H0) states that the two medications are equally effective, and is the hypothesis that the company hopes to reject using theone-tailed test.\n\nThe alternative hypothesis (Ha) states that the two drugs are not equally effective. This hypothesis\u00a0is the state of nature that is supported by rejecting the null hypothesis.\n\nThe biotech company implements a largeclinical trialof 3,000 patients with diabetes to compare the treatments. The company randomly divides the 3,000 patients into two equally sized groups, giving one group one of the treatments and the other group the other treatment.\n\nIt selects a significance level of 0.05, which indicates it is willing to accept a 5% chance it may reject the null hypothesis (a type I error).\n\nAssume the beta is calculated to be 0.025, or 2.5%. Therefore, the probability of committing a type II error is 97.5%.\n\nIf the two medications are not equal, the null hypothesis should be rejected. However, if the biotech company does not reject the null hypothesis when the drugs are not equally effective, then a type II error occurs.\n\nConsider the following question:\n\nYou would form two hypotheses from this question:\n\nYou would then set out to answer this question by conducting an experiment using a statistically significant number of humans. Once you recorded data on the population, you'd sort and analyze it, and draw conclusions about it.\n\nIt's pretty common knowledge that the older you get, the harder it is to see in the dark due to many factors, one of which is that the eye's rod cells become weaker with age.\n\nIf you conclude from your data that age doesn't affect how well humans see in the dark, you have failed to reject a false null hypothesis\u2014a type II error.\n\nIf, for some reason, age actually did not affect how well humans see in the dark, but your data showed it did, you would probably reject a true null hypothesis\u2014a type I error.\n\nA type I error occurs if a null hypothesis that is actually true in the population is rejected. Think of this type of error as a false positive. The type II error, which involves not rejecting a false null hypothesis, can be considered a false negative.\n\nA type II error is commonly caused if the statistical power of a test is too low. The higher the statistical power, the greater the chance of avoiding an error. It\u2019s often recommended that the statistical power should be set to at least 80% prior to conducting any testing.\n\nYou can lower the chances of a type II error by increasing the sample size of a study. As the true population effect size increases, the probability of a type II error should decrease. Additionally, the preset alpha level set by the research influences the magnitude of risk. As the alpha level set decreases, the risk of a type II error increases.\n\nIn statistics, a type II error is accepting a null hypothesis that should be rejected. A type II error can occur if there is not enough power in statistical tests, often resulting from sample sizes that are too small. Increasing the sample size can help reduce the chances of committing a type II error.\n\nYi, Hanxiao, et. al. \"A Meta-Analysis of Exosome in the Treatment of Spinal Cord Injury.\"Open Medicine, July 12, 2021. Vol 16, Pages 1043-1049.\n\nAmerican Academy of Ophthamology. \"21 Ways Aging Changes Your Eyes.\"",
  "url": "https://www.investopedia.com/terms/t/type-ii-error.asp"
}