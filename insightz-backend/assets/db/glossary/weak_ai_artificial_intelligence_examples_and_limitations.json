{
  "term": "Weak AI (Artificial Intelligence): Examples and Limitations",
  "definition": "Weak artificial intelligence (AI)\u2014also called narrow AI\u2014is a type ofartificial intelligencethat is limited to a specific or narrow area. Weak AI simulates human cognition. It has the potential to benefit society by automating time-consuming tasks and by analyzing data in ways that humans sometimes can\u2019t. Weak AI can be contrasted tostrong AI, a theoretical form of machine intelligence that is equal to human intelligence.\n\nWeak AI lacks human consciousness, although itmay be able to simulate it at times. The classic illustration of weak AI is John Searle's Chinese room thought experiment.This experiment says that a person outside a room may be able to have what appears to be a conversation in Chinese with a person inside a room who is being given instructions on how to respond to conversations in Chinese.\n\nIn this experiment, the person inside the room would appear to speak Chinese. In reality, they couldn't actually speak or understand a word of Chinese absent the instructions being fed. That's because the\u00a0person is good at following instructions, not speaking Chinese. They might appear to have strong AI\u2014machine intelligence equivalent to human intelligence\u2014but they really only have weak AI.\n\nNarrow or weak AI systems do not have general intelligence; they have specific intelligence. An AI that is an expert at telling you how to drive from point A to point B is usually incapable of challenging you to a game of chess. In the same way, a form of AI that can pretend to speak Chinese with you probably cannot sweep your floors.\n\nWeak AI helps turnbig datainto usable information by detecting patterns and making predictions. Examples of weak AI include Meta's (formerly Facebook) newsfeed, Amazon's suggested purchases,\u00a0and Apple's Siri, the iPhone technology thatanswers users' spoken questions.\n\nEmail spam filters are another example of weak AI; a computer uses an algorithm to learn which messages are likely to be spam, then redirects them from the inbox to the spam folder.\n\nBesides its limited capabilities, some of the problems with weak AI include the possibility to cause harm if a system fails\u00ad. For example, consider a driverless car that miscalculates the location of an oncoming vehicle and causes a deadly collision. The system also can cause harm if the system is used by someone who wishes to cause harm; consider a terrorist who uses a self-driving car to deploy explosives in a crowded area.\n\nA further concern related to weak AI is the loss of jobs caused by the automation of an increasing number of tasks. Will unemployment skyrocket, or will society develop new ways for humans to be economically productive? Although the prospect of a large percentage of workers losing their jobs may be terrifying, advocates of AI claim that it is also reasonable to expect that should this happen; new jobs will emerge that we can\u2019t yet predict as the use of AI becomes increasingly widespread.\n\nUniversity of Pennsylvania Carey School of Law. \"The Chinese Room Argument.\" Accessed Jan. 1, 2022.",
  "url": "https://www.investopedia.com/terms/w/weak-ai.asp"
}