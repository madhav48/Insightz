{
  "term": "Multicollinearity: Meaning, Examples, and FAQs",
  "definition": "Gordon Scott has been an active investor and technical analyst or 20+ years. He is a Chartered Market Technician (CMT).\n\nDavid is comprehensively experienced in many facets of financial and legal research and publishing. As an Investopedia fact checker since 2020, he has validated over 1,100 articles on a wide range of financial and investment topics.\n\nMulticollinearity is the occurrence of high intercorrelations among two or more independent variables in a multiple regression model.\u00a0Multicollinearity can lead to skewed or misleading results when a researcher or analyst attempts to determine how well each independent variable can be used most effectively to predict or understand the dependent variable in a statistical model.\n\nIn general, multicollinearity can lead to wider confidence intervals that produce less reliable probabilities in terms of the effect of independent variables in a model.\n\nIn technical analysis, multicollinearity can lead to incorrect assumptions about an investment. It generally occurs because multiple indicators of the same type have been used to analyze a stock.\n\nStatistical analysts usemultiple regression modelsto predict the value of a specified dependent variable based on the values of two or more independent variables. The dependent variable is sometimes called the outcome, target, or criterion variable.\n\nAn example is amultivariate regression modelthat attempts to anticipate stock returns based on metrics such as theprice-to-earnings ratio(P/E ratios), market capitalization, or other data. The stock return is the dependent variable (the outcome), and the various bits of financial data are the independent variables.\n\nMulticollinearity in a multiple regression model indicates that collinear independent variables are not truly independent. For example, past performance might be related tomarket capitalization. The stocks of businesses that have performed well experience investor confidence, increasing demand for that company's stock, which increases its market value.\n\nAlthough multicollinearity does not affect the regression estimates, it makes them vague, imprecise, and unreliable. Thus, it can be hard to determine how the independent variables influence the dependent variable individually. This inflatesthe standard errors of some or all of the regression coefficients.\n\nA statistical technique called thevariance inflation factor(VIF) can detect and measure the amount of collinearity in a multiple regression model. VIF measures how much the variance of the estimated regression coefficients is inflated as compared to when the predictor variables are not linearly related. A VIF of 1 will mean that the variables are not correlated; a VIF between 1 and 5 shows that variables are moderately correlated, and a VIF between 5 and 10 will mean that variables are highly correlated.\n\nWhen analyzing stocks, you can detect multicollinearity by noting whether the indicators graph the same. For instance, choosing two momentum indicators on a trading chart will generally create trend lines that indicate the same momentum.\n\nMulticollinearity can exist when two independent variables are highly correlated. It can also happen if an independent variable is computed from other variables in the data set or if two independent variables provide similar and repetitive results.\n\nAgain, if you're using the same data to create two or three of the same type of trading indicators, the outcomes will be multicollinear because the data and its manipulation to create the indicators are very similar.\n\nThe statistical inferences from a model that contains multicollinearity may not be dependable.\n\nPerfect multicollinearity demonstrates a linear relationship that is exact between multiple independent variables. This is usually seen on a chart where the data points fall along the regression line. In technical analysis, it can be seen when you use two indicators that measure the same thing, such as volume. If you overlaid one on top of the other, there would be no difference between them.\n\nHigh multicollinearity demonstrates a correlation between multiple independent variables, but it is not as tight as in perfect multicollinearity. Not all data points fall on the regression line, but it still signifies data is too tightly correlated to be used.\n\nIn technical analysis, indicators with high multicollinearity have very similar outcomes.\n\nStructural multicollinearity occurs when you use data to create new features. For instance, if you collected data and then used it to perform other calculations and ran a regression on the results, the outcomes will be correlated because they are derived from each other.\n\nThis is the type of multicollinearity seen in investment analysis because the same data is used to create different indicators.\n\nA poorly designed experiment or data collection process, such as using observational data, generally results in data-based multicollinearity, where data is correlated due to the nature of the way it was collected. Some or all of the variables are correlated.\n\nStock data used to create indicators is generally collected from historical prices and trading volume, so the chances of it being multicollinear due to a poor collection method are small.\n\nFor investing, multicollinearity is a common consideration when performingtechnical analysisto predict probable future price movements of a security, such as a stock or acommodity future.\n\nMarketanalystswant to avoid using technical indicators that are collinear in that they are based on very similar or related inputs; the inputs referred to here are not the data itself but how it was manipulated to achieve the outcome.\n\nInstead, the analysis must be based on markedly different indicators to ensure that the market is analyzed from independent analytical viewpoints. For example, momentum and trend indicators share the same data, but they will not be perfectly multicollinear or even demonstrate high multicollinearity. These two indicators have different outcomes based on how the data was manipulated.\n\nMost investors won't worry about the data and techniques behind the indicator calculations\u2014it's enough to understand what multicollinearity is and how it can affect an analysis.\n\nOne of the most common ways of eliminating the problem of multicollinearity is first to identify collinear independent predictors and then remove one or more of them. Generally, in statistics, a variance inflation factor calculation is run to determine the degree of multicollinearity. An alternative method for fixing multicollinearity is to collect more data under different conditions.\n\nNoted technical analyst John Bollinger, creator of theBollinger Bandsindicator, wrote that a \"cardinal rule for the successful use of technical analysis requires avoiding multicollinearity amid indicators.\"To solve the problem, analysts avoid using two or more technical indicators of the same type. Instead, they analyze a security using one type of indicator, such as amomentum indicator, and then do a separate analysis using a different type of indicator, such as a trend indicator.\n\nFor example,stochastics, therelative strength index(RSI), and Williams %R (Wm%R) are all momentum indicators that rely on similar inputs and are likely to produce similar results. In the image above, the stochastics and Wm%R are the same, so using them together doesn't reveal much. In this case, it is better to remove one of the indicators and use one that isn't tracking momentum. In the image below, stochastics show price momentum, and the Bollinger Band Width shows price consolidation before price movement.\n\nTo reduce the amount of multicollinearity found in a statistical model, one can remove the specific variables identified as the most collinear. You can also try to combine or transform the offending variables to lower their correlation. If that does not work or is unattainable, there are modified regression models that better deal with multicollinearity, such as ridge regression, principal component regression, or partial least squares regression. In stock analysis, the best method is to choose different types of indicators.\n\nMulticollinearity describes a relationship between variables that causes them to be correlated. Data with multicollinearity poses problems for analysis because they are not independent.\n\nData will have high multicollinearity when the variable inflation factor is more than five. If the VIF is between one and five, variables are moderately correlated, and if equal to one, they are not correlated. In technical analysis, the indicators will be generally identical.\n\nPerfect multicollinearity exists when there is an exact 1:1 correspondence between two independent variables in a model. This can be either a correlation of +1.0 or -1.0.\n\nMulticollinearity is a problem because it produces regression model results that are less reliable. This is due to wider confidence intervals (largerstandard errors) that can lower thestatistical significanceof regression coefficients. In stock analysis, it can lead to false impressions or assumptions about an investment.\n\nMulticollinearity exists whenever an independent variable is highly correlated with one or more of the other independent variables in a multiple regression equation. Multicollinearity is a problem because it will make the statistical inferences less reliable. However, the Variance Inflation Factor (VIF) can provide information about which variable or variables are redundant, and thus the variables that have a high VIF can be removed.\n\nWhen using technical analysis, multicollinearity becomes a problem because there are many indicators that present the data in the same way. To prevent this, it's best to use indicators that don't measure the same trend.\n\nPenn State Eberly College of Science. \u201c10.7 - Detecting Multicollinearity Using Variance Inflation Factors.\u201d\n\nBollinger, John. \u201cUsing Bollinger Bands.\u201dStocks & Commodities, vol. 10, no. 2, Feb. 1992, pp. 47-51.\n\nSenthilnathan, Samithamby. \u201cUsefulness of Correlation Analysis.\u201dSSRN Electronic Journal, July 2019, pp. 3-4.",
  "url": "https://www.investopedia.com/terms/m/multicollinearity.asp"
}